{"cells":[{"cell_type":"markdown","metadata":{"id":"tOIU9SaeIAz-"},"source":["# <center>Centro Universitário Facens<br/></center>\n","<br/>\n","<font size=\"4\"><center><b>Disciplina: Processamento de imagens</b></center></font>\n","  \n","<font size=\"3\"><center>Prof. Renato M. Silva</center></font>\n","<br/>\n","<br/>\n","\n","## <center>Avaliação Continuada 2 (AC2)</center>"]},{"cell_type":"markdown","metadata":{"id":"qSid38zgIhQM"},"source":["----\n","### <center>Nome e RA dos componentes do grupo</center>\n","\n","    \n","| Nome     |      RA      | \n","|:-        |:-------------:|\n","|Marcelo Zaguette Junior          | 180998               | \n","|Michel Micheloti          |181003              | \n","|Fernando Dias Motta          |180016              | \n","|          |              | \n","    "]},{"cell_type":"markdown","metadata":{"id":"DWHM72tmIhQN"},"source":["----\n","### Instruções\n","**1**. Siga boas práticas de programação:\n","- dar nomes intuitivos para as variáveis\n","- dar nomes intuitivos para as funções\n","\n","\n","**2**. O trabalho pode ser feito em grupos de até 5 pessoas, contendo alunos de qualquer uma das turmas da disciplina (CP405TIN1 e CP405TIN2). Apenas uma pessoa do grupo deve submeter o trabalho. Você deve submeter apenas o arquivo .ipynb.\n","\n","**3**. Cuidado com plágio. Se for detectado plágio entre grupos, a punição será dada para todos os componentes dos grupos envolvidos.\n","\n","**4**. Antes de submeter o notebook, certifique-se que não há erros de código. Uma forma de se certificar disso é usar a opção **\"Reiniciar Kernel e executar todas as células\"** do Jupyter ou a opção **\"Reiniciar e executar tudo\"** do Google Colab. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zb5KuIkKzCj"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import ctypes"]},{"cell_type":"markdown","metadata":{"id":"jNYwFJmFIhQO","tags":[]},"source":["----\n","## Exercício 1\n","\n","Implemente uma função que troque os quadrantes em diagonal na imagem e aplique na imagem **figs/lena.jpg**, conforme o primeiro exemplo abaixo. Em seguida, adicione a imagem **figs/facens.png** na imagem resultante, conforme mostrado no segundo exemplo abaixo. Por fim, mostre a imagem na tela.\n","\n","**Dica**: para remover o fundo da imagem **figs/facens.png**, você pode usar um algoritmo de segmentação, como por exemplo a limiarização. \n","\n","<center>\n","<div style=\"display:inline-block;\">\n","    <div>\n","    <div style=\"padding: 5px; float: left;\">\n","        <img src=\"imgNotebook/LenaQuadrantes.jpg\" width=\"255\" height=\"128\" />\n","    </div>\n","    <div style=\"padding: 5px; float: left;\">\n","        <img src=\"imgNotebook/LenaFacens.jpg\" width=\"255\" height=\"128\" />\n","    </div>   \n","</div> \n","</center>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9E-Cx-bcIhQO"},"outputs":[],"source":["def remove_background(img, threshold):\n","    \n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    _, threshed = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n","\n","    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n","    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n","\n","    cnts = cv2.findContours(morphed, \n","                            cv2.RETR_EXTERNAL,\n","                            cv2.CHAIN_APPROX_SIMPLE)[0]\n","\n","    cnt = sorted(cnts, key=cv2.contourArea)[-1]\n","\n","    mask = cv2.drawContours(threshed, cnt, 0, (0, 255, 0), 0)\n","    masked_data = cv2.bitwise_and(img, img, mask=mask)\n","\n","    dst = masked_data[0: 113, 0: 444]\n","\n","    dst_gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n","    _, alpha = cv2.threshold(dst_gray, 0, 255, cv2.THRESH_BINARY)\n","    b, g, r = cv2.split(dst)\n","\n","    rgba = [r, g, b, alpha]\n","    dst = cv2.merge(rgba, 4)\n","\n","    return dst\n","\n","initialImage = cv2.imread(\"figs/lena.jpg\")\n","lenaImageRGB = cv2.cvtColor(initialImage, cv2.COLOR_BGR2RGB)\n","lenaImage = cv2.cvtColor(lenaImageRGB, cv2.COLOR_BGR2GRAY)\n","cv2.imwrite('lenaImageGray.png', lenaImage)\n","\n","crop_img_quad1 = lenaImage[0:256, 256:512]\n","crop_img_quad2 = lenaImage[0:256, 0:256]\n","crop_img_quad3 = lenaImage[256:512, 0:256]\n","crop_img_quad4 = lenaImage[256:512, 256:512]\n","visVertical1 = np.concatenate((crop_img_quad4,crop_img_quad3), axis=0)\n","visVertical2 = np.concatenate((crop_img_quad1,crop_img_quad2), axis=0)\n","reorganizedImage = np.concatenate((visVertical1,visVertical2), axis=1)\n","cv2.imwrite('reorganizedImageLena.png', reorganizedImage)\n","reorganizedImage = cv2.imread(\"reorganizedImageLena.png\")\n","\n","facensLogo = cv2.imread('figs/facens.png')\n","\n","noBackgroud = remove_background(facensLogo, threshold=250.)\n","\n","cv2.imwrite(\"noBackgroundTest.png\",noBackgroud)\n","\n","finalImage = cv2.imread('reorganizedImageLena.png')\n","coloredFacensLogo = cv2.imread('noBackgroundTest.png')\n","\n","ret, facensLogo = cv2.threshold(coloredFacensLogo, 0, 255, cv2.THRESH_BINARY)\n","\n","rows,cols,channels = facensLogo.shape\n","roi = finalImage[399:rows+399, 0:cols]\n","facensLogogray = cv2.cvtColor(facensLogo,cv2.COLOR_BGR2GRAY)\n","ret, mask = cv2.threshold(facensLogogray, 10, 255, cv2.THRESH_BINARY)\n","mask_inv = cv2.bitwise_not(mask)\n","finalImage_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n","\n","facensLogo_fg = cv2.bitwise_and(facensLogo,facensLogo,mask = mask_inv)\n","dst = cv2.add(finalImage_bg,facensLogo_fg)\n","finalImage[399: rows+399, 0:cols ] = dst\n","\n","\n","black_pixels = np.where(\n","    (finalImage[:, :, 0] == 0) & \n","    (finalImage[:, :, 1] == 0) & \n","    (finalImage[:, :, 2] == 0)\n",")\n","\n","finalImage[black_pixels] = [255, 255, 255]\n","plt.imshow(finalImage)\n","plt.title(\"Final Image\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"rG04L2S1IhQP"},"source":["----\n","## Exercício 2\n","\n","Implemente uma função que consiga fazer a detecção de movimentos em um vídeo. Ela deverá extrair os frames do vídeo e para cada frame, ele deve calcular o histograma da imagem e compará-lo com o último histograma calculado. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, simule um alarme interrompendo a função e retornando uma mensagem de alerta. Utilize uma função de comparação que julgar conveniente. \n","\n","Teste a função no vídeo *videos/cameraEscondida.mp4*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-OosI5dH9Q_"},"outputs":[],"source":["##### Resolva o exercício aqui\n","\n","cap = cv2.VideoCapture('videos/cameraEscondida.mp4')\n","\n","background = None\n","\n","if (cap.isOpened()== False): \n","  print(\"Error opening video stream or file\")\n","\n","hist = []\n","while(cap.isOpened()):\n","  ret, frame = cap.read()\n","  if ret == True:\n","    i=0\n","\n","    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n","\n","    gray = cv2.GaussianBlur(gray,(21,21), 0)\n","    \n","    if background is None:\n","      background = gray\n","    \n","    subtraction = cv2.absdiff(background, gray)\n","\n","    _,threshold = cv2.threshold (subtraction, 25, 255, cv2.THRESH_BINARY)\n","\n","    threshold = cv2.dilate(threshold, None, iterations=2)\n","\n","    contourimg = threshold.copy() \n","\n","    outlines, hierarchy = cv2.findContours(contourimg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    hist.append(cv2.calcHist([contourimg], [0], None, [256], [0, 256]))\n","\n","    if hist[i][0] - hist[i-1][0] >= 500:\n","      ctypes.windll.user32.MessageBoxW(0, \"Este é um bom momento para ter amor a vida\", \"Esconda-se\", 1)\n","      break\n","\n","    cv2.imshow(\"Camera\",frame)\n","    # cv2.imshow(\"Threshold\",threshold)\n","    # cv2.imshow(\"Substraction\",subtraction)\n","    # cv2.imshow(\"Contour\",contourimg)\n","    i=i+1\n","    if cv2.waitKey(25) & 0xFF == ord('q'):\n","      break\n","\n","  # Break the loop\n","  else: \n","    break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{"id":"1pwLlimqIhQR"},"source":["----\n","## Exercicio 3\n","\n","Por meio de operações morfológicas e outras técnicas aprendidas na disciplina, destaque o arroz da imagem **figs/arroz.tif**. Você deve salvar a nova imagem com o nome **arroz_destacado.jpg**. Abaixo é mostrado um exemplo do resultado esperado.\n","\n","<img src=\"imgNotebook/arroz.png\" width=\"410\" height=\"128\" />"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HHOS2RQPIhQR"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/arroz.tif', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem Original')\n","plt.show()\n","\n","kernel = np.ones((5,5),np.uint8)\n","thresh2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 199, 5) \n","opening = cv2.morphologyEx(thresh2, cv2.MORPH_OPEN, kernel)\n","\n","plt.imshow(opening, 'gray')\n","plt.title('Imagem Final')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Rmp90DzPIhQS"},"source":["----\n","## Exercicio 4\n","\n","Remova o ruído das imagens **figs/casa.png** e **figs/placa.tif**. Depois, mostre a imagem restaurada na tela."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6V4qVeIDIhQS"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/casa.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('figs/placa.tif', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem CASA Original')\n","plt.show()\n","\n","kernel = np.ones((5,5),np.uint8)\n","sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n","median = cv2.medianBlur(img,5)\n","sharpen = cv2.filter2D(median, -1, sharpen_kernel)\n","plt.imshow(sharpen, 'gray')\n","plt.title('Img CASA Processada')\n","plt.show()\n","\n","plt.imshow(img2, 'gray')\n","plt.title('Imagem PLACA Original')\n","plt.show()\n","\n","median2 = cv2.medianBlur(img2,5)\n","sharpen2 = cv2.filter2D(median2, -1, sharpen_kernel)\n","plt.imshow(sharpen2, 'gray')\n","plt.title('Imagem PLACA Processada')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"3p5FBGlIIhQS"},"source":["----\n","## Exercicio 5\n","\n","Utilize operações morfológicas nas imagens **figs/manequim.png** e **figs/tabuleiro.jpg** para remover os pontos brancos. Depois, mostre as imagens restauradas na tela."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WZNqJhuIhQT"},"outputs":[],"source":["##### Resolva o exercício aqui\n","kernel = np.ones((5,5),np.uint8)\n","\n","img = cv2.imread('figs/manequim.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('figs/tabuleiro.png', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem 1 Original')\n","plt.show()\n","\n","imgOpening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n","plt.imshow(imgOpening, 'gray')\n","plt.title('Img 1 Limpa')\n","plt.show()\n","\n","plt.imshow(img2, 'gray')\n","plt.title('Imagem 2 Original')\n","plt.show()\n","\n","img2Opening = cv2.morphologyEx(img2, cv2.MORPH_RECT, kernel)\n","img2Opening = cv2.morphologyEx(img2Opening, cv2.MORPH_RECT, kernel)\n","\n","plt.imshow(img2Opening, 'gray')\n","plt.title('Img 2 Limpa')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"n2J5lMG5IhQT"},"source":["----\n","## Exercicio 6\n","\n","Por meio de operações morfológicas, remova o círculos menores da imagem **figs/circulos.tif**, deixando apenas os círculos maiores. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdZqGcUQIhQT"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/circulos.tif', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem Original')\n","plt.show()\n","\n","kernel = np.ones((5,5),np.uint8)\n","dilation = cv2.dilate(img,kernel,iterations = 9)\n","erosion = cv2.erode(dilation,kernel,iterations = 5)\n","\n","plt.imshow(erosion, 'gray')\n","plt.title('Imagem Processada')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"u3NIY2qdIhQU"},"source":["----\n","## Exercicio 7\n","\n","Aplique um filtro Gaussiano na imagem **figs/lena_noise.png** para diminuir o ruído e mostre na tela. Depois, faça a detecção de bordas da imagem resultante usando as seguintes técnicas: Sobel, Prewitt e Frei-Chen. Mostre na tela os resultado obtido após cada uma das técnicas de detecção de bordas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUUtuQWGIhQU"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/lena_noise.png', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem Lena Original')\n","plt.show()\n","\n","\n","blur = cv2.GaussianBlur(img,(11,11),0)\n","\n","plt.imshow(blur, 'gray')\n","plt.title('Imagem Lena Filtro Gaussiano')\n","plt.show()\n","\n","dst = cv2.equalizeHist(blur)\n","\n","plt.imshow(dst, 'gray')\n","plt.title('Imagem Lena equalizeHist')\n","plt.show()\n","\n","sobel_x = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n","sobel_y = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n","\n","sobel_xy = np.maximum(sobel_x, sobel_y)\n","\n","scale = 1\n","delta = 0\n","ddepth = cv2.CV_16S\n","\n","grad_x = cv2.Sobel(dst, ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n","grad_y = cv2.Sobel(dst, ddepth, 0, 1, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n","\n","abs_grad_x = cv2.convertScaleAbs(grad_x)\n","abs_grad_y = cv2.convertScaleAbs(grad_y)\n","grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n","\n","plt.imshow(grad, 'gray')\n","plt.title('Imagem Lena Bordas Sobel')\n","plt.show()\n","\n","\n","kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n","kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n","img_prewittx = cv2.filter2D(dst, -1, kernelx)\n","img_prewitty = cv2.filter2D(dst, -1, kernely)\n","\n","img_prewitt = img_prewittx + img_prewitty\n","\n","plt.imshow(img_prewitt,'gray')\n","plt.title(\"Imagem Lena Bordas Prewitt\")\n","plt.show()\n","\n","\n","#Frei-Chen\n"]},{"cell_type":"markdown","metadata":{"id":"lKep5d1cIhQU"},"source":["----\n","## Exercicio 8\n","\n","Por meio das técnicas aprendidas na disciplina, tente melhorar o **máximo** possível a imagem **figs/lena_pontilhada.png**. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fB7eUUEIhQV"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/lena_pontilhada.png', cv2.IMREAD_GRAYSCALE)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem CASA Original')\n","plt.show()\n","\n","kernel = np.ones((5,5),np.uint8)\n","sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n","\n","\n","median = cv2.medianBlur(img,1)\n","\n","rect = cv2.morphologyEx(median, cv2.MORPH_RECT, kernel)\n","dilate = cv2.dilate(rect,kernel,iterations = 1)\n","gaussBlur = cv2.GaussianBlur(dilate,(25,25), 0)\n","\n","plt.imshow(gaussBlur, 'gray')\n","plt.title('Imagem Sharpen Processada')\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mvicCEevIhQW"},"source":["----\n","## Exercicio 9\n","\n","Aplique um filtro para borrar as extremidades da imagem **figs/vista.jpg** para que ela fique com o efeito mostrado na imagem abaixo.\n","\n","<img src=\"imgNotebook/vista_blur.jpg\" width=\"500\" height=\"128\" />"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ge-ALLTQIhQW"},"outputs":[],"source":["##### Resolva o exercício aqui\n","img = cv2.imread('figs/vista.jpg')\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem Original')\n","plt.show()\n","\n","top = int(0 * img.shape[0])\n","bottom = top\n","left = int(0.05 * img.shape[1])\n","right = left\n","\n","dst = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_REPLICATE, cv2.GaussianBlur(gray,(21,21), 0))\n","\n","scale_percent = 200 # percent of original size\n","width = int(dst.shape[1] * scale_percent / 100)\n","height = int(dst.shape[0])\n","dim = (width, height)\n","\n","resized = cv2.resize(dst, dim, interpolation = cv2.INTER_AREA)\n","\n","blur = cv2.blur(resized,(20,20))\n","\n","plt.imshow(blur, 'gray')\n","plt.title('Imagem Processada')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qvlNAHtcIhQX"},"source":["----\n","## Exercicio 10\n","\n","As imagens **Degraded_A.jpg** e **Degraded_B.jpg** possuem algum grau de degradação. Melhore a qualidade dessas imagens com as técnicas aprendidas na disciplina e mostre o resultado na tela. O resultado final deve ser o mais próximo possível da imagem original mostrada abaixo. \n","\n","<img src=\"imgNotebook/Desired.jpg\" width=\"250\" />"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MvA1YmeIhQX"},"outputs":[],"source":["img = cv2.imread('figs/Degraded_A.jpg')\n","img2 = cv2.imread('figs/Degraded_D.jpg')\n","\n","median = cv2.medianBlur(img,5)\n","cv2.imwrite(\"exe10_img.jpg\",median)\n","\n","\n","sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n","sharpen = cv2.filter2D(img2, -1, sharpen_kernel)\n","\n","cv2.imwrite(\"exe10_img2.jpg\",sharpen)\n","\n","imgFinal1 = cv2.imread('exe10_img.jpg')\n","imgFinal2 = cv2.imread('exe10_img2.jpg')\n","\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n","imgFinal1 = cv2.cvtColor(imgFinal1, cv2.COLOR_BGR2RGB)\n","imgFinal2 = cv2.cvtColor(imgFinal2, cv2.COLOR_BGR2RGB)\n","\n","plt.imshow(img, 'gray')\n","plt.title('Imagem Cidade 1 Original')\n","plt.show()\n","\n","plt.imshow(img2, 'gray')\n","plt.title('Imagem Cidade 2 Original')\n","plt.show()\n","\n","plt.imshow(imgFinal1)\n","plt.title('Imagem Cidade 1 Processada')\n","plt.show()\n","\n","plt.imshow(imgFinal2)\n","plt.title('Imagem Cidade 2 Processada')\n","plt.show()\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"exerciciosPraticos.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
